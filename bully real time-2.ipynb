{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "import umap\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "import pythainlp\n",
    "from pythainlp.corpus.common import thai_words\n",
    "from pythainlp.util import Trie\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('7204.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>อีตัวเงินตัวทอง</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>น่าสงสาร สัมภเวสี พวกเศษขยะอย่างพวกมึง</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ไม่ชั่วทำไม่ได้นะ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ปากบอกไม่เป็นไรๆแต่ในใจโกรธและเสียหน้ามาก นางม...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>คำว่า ผู้ดี กับ ไพร่</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ดูได้จากปฏิกริยา ความคิด กมลสันดาน และการกระทำ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ขอบคุณป้าที่ทำให้เห็นธาตุแท้ของคนบางคนยิ่งขึ้น</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>เขารู้ว่าเป็นคนเลวเขาจึงไม่ให้ถ่ายไง</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>จิตใจคิดร้ายหวังให้เขาเสื่อมเสีย</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>คุณป้าท่านสุภาพเป็นผู้ดีพอพูดจาไพเราะขอไห้ขายด...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  label\n",
       "0                                    อีตัวเงินตัวทอง      1\n",
       "1             น่าสงสาร สัมภเวสี พวกเศษขยะอย่างพวกมึง      1\n",
       "2                                  ไม่ชั่วทำไม่ได้นะ      1\n",
       "3  ปากบอกไม่เป็นไรๆแต่ในใจโกรธและเสียหน้ามาก นางม...      1\n",
       "4                              คำว่า ผู้ดี กับ ไพร่       0\n",
       "5    ดูได้จากปฏิกริยา ความคิด กมลสันดาน และการกระทำ       0\n",
       "6     ขอบคุณป้าที่ทำให้เห็นธาตุแท้ของคนบางคนยิ่งขึ้น      0\n",
       "7               เขารู้ว่าเป็นคนเลวเขาจึงไม่ให้ถ่ายไง      0\n",
       "8                   จิตใจคิดร้ายหวังให้เขาเสื่อมเสีย      0\n",
       "9  คุณป้าท่านสุภาพเป็นผู้ดีพอพูดจาไพเราะขอไห้ขายด...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    576\n",
       "1    374\n",
       "9      1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_characters = \"/[!@#$%^&*']/g\"\n",
    "\n",
    "specialchar_pattern = re.compile(special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_pattern = re.compile(\"[0-9]\")\n",
    "space_pattern = re.compile(\"\\s+\")\n",
    "dot_pattern = re.compile(r\"\\.+\")\n",
    "backslash_pattern = re.compile(r\"\\\\+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(pythainlp.corpus.thai_stopwords())\n",
    "removed_words = ['u', 'b', 'n', 'nn', 'nn-', '\\n']\n",
    "screening_words = stopwords + removed_words\n",
    "\n",
    "new_words = {'สามกีบ','มารศาสนา'}\n",
    "\n",
    "words = new_words.union(thai_words())\n",
    "\n",
    "custom_dictionary_trie = Trie(words)\n",
    "\n",
    "def tokenize_to_list(sentence):\n",
    "  merged = []\n",
    "  words = pythainlp.word_tokenize(str(sentence), engine='newmm', custom_dict=custom_dictionary_trie)\n",
    "  for word in words:\n",
    "    if word not in screening_words:\n",
    "      merged.append(word)\n",
    "  return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final(sentence):\n",
    "  merged = ''\n",
    "  words = pythainlp.word_tokenize(str(sentence), engine='newmm', custom_dict=custom_dictionary_trie)\n",
    "  for word in words:\n",
    "    if word not in screening_words:\n",
    "      merged=merged+word\n",
    "  return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>อีตัวเงินตัวทอง</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>น่าสงสาร สัมภเวสี พวกเศษขยะอย่างพวกมึง</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ไม่ชั่วทำไม่ได้นะ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ปากบอกไม่เป็นไรๆแต่ในใจโกรธและเสียหน้ามาก นางม...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>คำว่า ผู้ดี กับ ไพร่</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>ยุคนี้มันเสรีแล้ว รักใครก็ได้ขอให้รักกันก็พอ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>ความรักคือความเข้าใจกัน</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>ยิ่งเวลาเมานี่พูดสนุกปากเลยแต่ละคน</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>น่าอาย ขุดทอง</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>พวกสายเหลือง</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>951 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment  label\n",
       "0                                      อีตัวเงินตัวทอง      1\n",
       "1               น่าสงสาร สัมภเวสี พวกเศษขยะอย่างพวกมึง      1\n",
       "2                                    ไม่ชั่วทำไม่ได้นะ      1\n",
       "3    ปากบอกไม่เป็นไรๆแต่ในใจโกรธและเสียหน้ามาก นางม...      1\n",
       "4                                คำว่า ผู้ดี กับ ไพร่       0\n",
       "..                                                 ...    ...\n",
       "946       ยุคนี้มันเสรีแล้ว รักใครก็ได้ขอให้รักกันก็พอ      0\n",
       "947                            ความรักคือความเข้าใจกัน      0\n",
       "948                 ยิ่งเวลาเมานี่พูดสนุกปากเลยแต่ละคน      0\n",
       "949                                      น่าอาย ขุดทอง      1\n",
       "950                                       พวกสายเหลือง      1\n",
       "\n",
       "[951 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment'] = df['comment'].apply(lambda x: emoji_pattern.sub(r'', x))\n",
    "df['comment'] = df['comment'].apply(lambda x: specialchar_pattern.sub(r'', x))\n",
    "df['comment'] = df['comment'].apply(lambda x: number_pattern.sub(r'', x))\n",
    "df['comment'] = df['comment'].apply(lambda x: space_pattern.sub(r'', x))\n",
    "df['comment'] = df['comment'].apply(lambda x: dot_pattern.sub(r'', x))\n",
    "df['comment'] = df['comment'].apply(lambda x: backslash_pattern.sub(r'', x))\n",
    "df['texts_tokenized'] = df['comment'].apply(lambda x: tokenize_to_list(x))\n",
    "df['final']=df['comment'].apply(lambda x: final(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "      <th>texts_tokenized</th>\n",
       "      <th>final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>อีตัวเงินตัวทอง</td>\n",
       "      <td>1</td>\n",
       "      <td>[อี, ตัวเงินตัวทอง]</td>\n",
       "      <td>อีตัวเงินตัวทอง</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>น่าสงสารสัมภเวสีพวกเศษขยะอย่างพวกมึง</td>\n",
       "      <td>1</td>\n",
       "      <td>[น่าสงสาร, สัมภเวสี, เศษ, ขยะ]</td>\n",
       "      <td>น่าสงสารสัมภเวสีเศษขยะ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ไม่ชั่วทำไม่ได้นะ</td>\n",
       "      <td>1</td>\n",
       "      <td>[ชั่ว, ทำ]</td>\n",
       "      <td>ชั่วทำ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ปากบอกไม่เป็นไรๆแต่ในใจโกรธและเสียหน้ามากนางมี...</td>\n",
       "      <td>1</td>\n",
       "      <td>[ปาก, ใจ, โกรธ, เสียหน้า, ปม, ใจ, อยู่แล้ว, คน...</td>\n",
       "      <td>ปากใจโกรธเสียหน้าปมใจอยู่แล้วคนต้อนรับโวยวายน่...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>คำว่าผู้ดีกับไพร่</td>\n",
       "      <td>0</td>\n",
       "      <td>[ผู้ดี, ไพร่]</td>\n",
       "      <td>ผู้ดีไพร่</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>ยุคนี้มันเสรีแล้วรักใครก็ได้ขอให้รักกันก็พอ</td>\n",
       "      <td>0</td>\n",
       "      <td>[ยุค, เสรี, รัก, ใครก็ได้, ขอให้, รัก]</td>\n",
       "      <td>ยุคเสรีรักใครก็ได้ขอให้รัก</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>ความรักคือความเข้าใจกัน</td>\n",
       "      <td>0</td>\n",
       "      <td>[ความรัก, ความเข้าใจ]</td>\n",
       "      <td>ความรักความเข้าใจ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>ยิ่งเวลาเมานี่พูดสนุกปากเลยแต่ละคน</td>\n",
       "      <td>0</td>\n",
       "      <td>[เวลา, เมา, สนุกปาก, แต่ละคน]</td>\n",
       "      <td>เวลาเมาสนุกปากแต่ละคน</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>น่าอายขุดทอง</td>\n",
       "      <td>1</td>\n",
       "      <td>[น่าอาย, ขุด, ทอง]</td>\n",
       "      <td>น่าอายขุดทอง</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>พวกสายเหลือง</td>\n",
       "      <td>1</td>\n",
       "      <td>[สาย, เหลือง]</td>\n",
       "      <td>สายเหลือง</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>951 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment  label  \\\n",
       "0                                      อีตัวเงินตัวทอง      1   \n",
       "1                 น่าสงสารสัมภเวสีพวกเศษขยะอย่างพวกมึง      1   \n",
       "2                                    ไม่ชั่วทำไม่ได้นะ      1   \n",
       "3    ปากบอกไม่เป็นไรๆแต่ในใจโกรธและเสียหน้ามากนางมี...      1   \n",
       "4                                    คำว่าผู้ดีกับไพร่      0   \n",
       "..                                                 ...    ...   \n",
       "946        ยุคนี้มันเสรีแล้วรักใครก็ได้ขอให้รักกันก็พอ      0   \n",
       "947                            ความรักคือความเข้าใจกัน      0   \n",
       "948                 ยิ่งเวลาเมานี่พูดสนุกปากเลยแต่ละคน      0   \n",
       "949                                       น่าอายขุดทอง      1   \n",
       "950                                       พวกสายเหลือง      1   \n",
       "\n",
       "                                       texts_tokenized  \\\n",
       "0                                  [อี, ตัวเงินตัวทอง]   \n",
       "1                       [น่าสงสาร, สัมภเวสี, เศษ, ขยะ]   \n",
       "2                                           [ชั่ว, ทำ]   \n",
       "3    [ปาก, ใจ, โกรธ, เสียหน้า, ปม, ใจ, อยู่แล้ว, คน...   \n",
       "4                                        [ผู้ดี, ไพร่]   \n",
       "..                                                 ...   \n",
       "946             [ยุค, เสรี, รัก, ใครก็ได้, ขอให้, รัก]   \n",
       "947                              [ความรัก, ความเข้าใจ]   \n",
       "948                      [เวลา, เมา, สนุกปาก, แต่ละคน]   \n",
       "949                                 [น่าอาย, ขุด, ทอง]   \n",
       "950                                      [สาย, เหลือง]   \n",
       "\n",
       "                                                 final  \n",
       "0                                      อีตัวเงินตัวทอง  \n",
       "1                               น่าสงสารสัมภเวสีเศษขยะ  \n",
       "2                                               ชั่วทำ  \n",
       "3    ปากใจโกรธเสียหน้าปมใจอยู่แล้วคนต้อนรับโวยวายน่...  \n",
       "4                                            ผู้ดีไพร่  \n",
       "..                                                 ...  \n",
       "946                         ยุคเสรีรักใครก็ได้ขอให้รัก  \n",
       "947                                  ความรักความเข้าใจ  \n",
       "948                              เวลาเมาสนุกปากแต่ละคน  \n",
       "949                                       น่าอายขุดทอง  \n",
       "950                                          สายเหลือง  \n",
       "\n",
       "[951 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data.label\n",
    "x=data.final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=data.texts_tokenized, vector_size=100, window=5, min_count=5, workers=4, sg=0, epochs=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xtest,Ytrain,Ytest=train_test_split(x,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macproretina132015/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "\n",
      "30225\n",
      "(30225, 300)\n"
     ]
    }
   ],
   "source": [
    "with open('th.tsv') as f:\n",
    "  vocab = []\n",
    "  W = None\n",
    "  vec = ''\n",
    "  for line in f.readlines():\n",
    "    temp = line.split('\\t')\n",
    "    if len(temp) == 3:\n",
    "      vocab.append(temp[1])\n",
    "      if int(temp[0]) % 1000 == 0:\n",
    "        print('\\r' + temp[0], end='')\n",
    "      wordvector = np.fromstring(re.sub('\\s+', ' ', vec)[1:-1], sep=' ', dtype=np.float32)\n",
    "      if len(wordvector) > 0:\n",
    "        if W is None:\n",
    "          W = wordvector.copy()\n",
    "        else:\n",
    "          W = np.vstack((W, wordvector))\n",
    "      vec = temp[-1]\n",
    "    elif len(temp) == 1:\n",
    "      vec += temp[-1]\n",
    "  W = np.vstack((W, wordvector))\n",
    "print('\\n')\n",
    "print(len(vocab))\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attacut import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2idx(x):\n",
    "  xidx = []\n",
    "  for w in tokenize(x):\n",
    "    if w in vocab:\n",
    "      xidx.append(vocab.index(w))\n",
    "  return np.array(xidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "10\n",
      "2\n",
      "24\n",
      "9\n",
      "4\n",
      "4\n",
      "4\n",
      "1\n",
      "9\n",
      "0\n",
      "9\n",
      "11\n",
      "8\n",
      "8\n",
      "3\n",
      "13\n",
      "3\n",
      "14\n",
      "4\n",
      "6\n",
      "2\n",
      "7\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "7\n",
      "2\n",
      "2\n",
      "10\n",
      "12\n",
      "4\n",
      "4\n",
      "4\n",
      "8\n",
      "4\n",
      "4\n",
      "6\n",
      "3\n",
      "13\n",
      "4\n",
      "9\n",
      "6\n",
      "9\n",
      "11\n",
      "3\n",
      "5\n",
      "9\n",
      "10\n",
      "8\n",
      "7\n",
      "1\n",
      "8\n",
      "1\n",
      "2\n",
      "15\n",
      "1\n",
      "9\n",
      "5\n",
      "6\n",
      "3\n",
      "4\n",
      "0\n",
      "6\n",
      "9\n",
      "4\n",
      "3\n",
      "7\n",
      "3\n",
      "4\n",
      "2\n",
      "5\n",
      "4\n",
      "12\n",
      "8\n",
      "3\n",
      "9\n",
      "6\n",
      "5\n",
      "7\n",
      "3\n",
      "3\n",
      "6\n",
      "5\n",
      "6\n",
      "1\n",
      "3\n",
      "2\n",
      "10\n",
      "5\n",
      "10\n",
      "0\n",
      "3\n",
      "10\n",
      "16\n",
      "7\n",
      "12\n",
      "2\n",
      "3\n",
      "7\n",
      "4\n",
      "9\n",
      "4\n",
      "2\n",
      "12\n",
      "4\n",
      "2\n",
      "8\n",
      "10\n",
      "2\n",
      "5\n",
      "7\n",
      "2\n",
      "4\n",
      "1\n",
      "2\n",
      "1\n",
      "7\n",
      "3\n",
      "6\n",
      "0\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "7\n",
      "2\n",
      "18\n",
      "5\n",
      "8\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "11\n",
      "10\n",
      "4\n",
      "8\n",
      "6\n",
      "5\n",
      "5\n",
      "15\n",
      "2\n",
      "1\n",
      "2\n",
      "7\n",
      "4\n",
      "1\n",
      "4\n",
      "0\n",
      "6\n",
      "9\n",
      "23\n",
      "4\n",
      "0\n",
      "10\n",
      "9\n",
      "5\n",
      "3\n",
      "3\n",
      "6\n",
      "4\n",
      "3\n",
      "10\n",
      "5\n",
      "7\n",
      "2\n",
      "4\n",
      "5\n",
      "4\n",
      "1\n",
      "4\n",
      "5\n",
      "4\n",
      "3\n",
      "14\n",
      "3\n",
      "3\n",
      "6\n",
      "13\n",
      "9\n",
      "4\n",
      "5\n",
      "5\n",
      "1\n",
      "2\n",
      "5\n",
      "3\n",
      "9\n",
      "13\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "7\n",
      "22\n",
      "2\n",
      "11\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "8\n",
      "4\n",
      "1\n",
      "1\n",
      "2\n",
      "6\n",
      "5\n",
      "5\n",
      "3\n",
      "6\n",
      "1\n",
      "11\n",
      "3\n",
      "5\n",
      "5\n",
      "8\n",
      "2\n",
      "3\n",
      "1\n",
      "0\n",
      "3\n",
      "7\n",
      "3\n",
      "6\n",
      "12\n",
      "4\n",
      "9\n",
      "5\n",
      "2\n",
      "13\n",
      "6\n",
      "9\n",
      "13\n",
      "2\n",
      "4\n",
      "8\n",
      "0\n",
      "6\n",
      "5\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "12\n",
      "8\n",
      "5\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "19\n",
      "2\n",
      "2\n",
      "0\n",
      "3\n",
      "7\n",
      "2\n",
      "5\n",
      "11\n",
      "6\n",
      "6\n",
      "3\n",
      "15\n",
      "14\n",
      "9\n",
      "6\n",
      "2\n",
      "5\n",
      "4\n",
      "2\n",
      "7\n",
      "9\n",
      "0\n",
      "12\n",
      "7\n",
      "4\n",
      "4\n",
      "0\n",
      "19\n",
      "3\n",
      "11\n",
      "4\n",
      "4\n",
      "2\n",
      "1\n",
      "6\n",
      "8\n",
      "8\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "17\n",
      "6\n",
      "14\n",
      "9\n",
      "0\n",
      "3\n",
      "4\n",
      "10\n",
      "2\n",
      "21\n",
      "5\n",
      "1\n",
      "6\n",
      "3\n",
      "15\n",
      "2\n",
      "1\n",
      "3\n",
      "3\n",
      "13\n",
      "12\n",
      "34\n",
      "6\n",
      "4\n",
      "5\n",
      "2\n",
      "8\n",
      "4\n",
      "5\n",
      "4\n",
      "12\n",
      "23\n",
      "3\n",
      "7\n",
      "3\n",
      "2\n",
      "7\n",
      "16\n",
      "4\n",
      "12\n",
      "2\n",
      "6\n",
      "6\n",
      "5\n",
      "8\n",
      "6\n",
      "1\n",
      "11\n",
      "1\n",
      "11\n",
      "5\n",
      "1\n",
      "11\n",
      "15\n",
      "7\n",
      "3\n",
      "8\n",
      "8\n",
      "9\n",
      "5\n",
      "9\n",
      "7\n",
      "5\n",
      "9\n",
      "4\n",
      "6\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "9\n",
      "3\n",
      "5\n",
      "13\n",
      "9\n",
      "16\n",
      "9\n",
      "5\n",
      "3\n",
      "12\n",
      "10\n",
      "10\n",
      "3\n",
      "1\n",
      "31\n",
      "2\n",
      "2\n",
      "5\n",
      "5\n",
      "9\n",
      "9\n",
      "2\n",
      "1\n",
      "11\n",
      "11\n",
      "2\n",
      "1\n",
      "12\n",
      "0\n",
      "10\n",
      "7\n",
      "2\n",
      "7\n",
      "4\n",
      "9\n",
      "6\n",
      "7\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "7\n",
      "3\n",
      "12\n",
      "2\n",
      "11\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "3\n",
      "3\n",
      "15\n",
      "5\n",
      "7\n",
      "5\n",
      "7\n",
      "4\n",
      "0\n",
      "5\n",
      "6\n",
      "9\n",
      "1\n",
      "10\n",
      "3\n",
      "1\n",
      "13\n",
      "0\n",
      "3\n",
      "1\n",
      "1\n",
      "2\n",
      "4\n",
      "4\n",
      "6\n",
      "0\n",
      "8\n",
      "6\n",
      "1\n",
      "14\n",
      "1\n",
      "3\n",
      "14\n",
      "8\n",
      "5\n",
      "4\n",
      "9\n",
      "1\n",
      "6\n",
      "5\n",
      "7\n",
      "2\n",
      "6\n",
      "7\n",
      "3\n",
      "2\n",
      "10\n",
      "1\n",
      "8\n",
      "5\n",
      "13\n",
      "11\n",
      "0\n",
      "14\n",
      "15\n",
      "3\n",
      "7\n",
      "5\n",
      "8\n",
      "4\n",
      "9\n",
      "6\n",
      "11\n",
      "5\n",
      "13\n",
      "4\n",
      "1\n",
      "2\n",
      "10\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "9\n",
      "4\n",
      "4\n",
      "8\n",
      "12\n",
      "15\n",
      "14\n",
      "5\n",
      "2\n",
      "8\n",
      "2\n",
      "8\n",
      "1\n",
      "4\n",
      "22\n",
      "5\n",
      "10\n",
      "4\n",
      "2\n",
      "12\n",
      "1\n",
      "7\n",
      "1\n",
      "5\n",
      "1\n",
      "5\n",
      "2\n",
      "9\n",
      "3\n",
      "0\n",
      "4\n",
      "10\n",
      "5\n",
      "7\n",
      "2\n",
      "2\n",
      "11\n",
      "3\n",
      "2\n",
      "11\n",
      "5\n",
      "7\n",
      "10\n",
      "4\n",
      "0\n",
      "0\n",
      "9\n",
      "12\n",
      "2\n",
      "6\n",
      "1\n",
      "0\n",
      "5\n",
      "12\n",
      "1\n",
      "1\n",
      "4\n",
      "13\n",
      "4\n",
      "2\n",
      "7\n",
      "6\n",
      "1\n",
      "3\n",
      "6\n",
      "14\n",
      "1\n",
      "5\n",
      "4\n",
      "2\n",
      "12\n",
      "1\n",
      "2\n",
      "5\n",
      "4\n",
      "7\n",
      "4\n",
      "1\n",
      "1\n",
      "2\n",
      "8\n",
      "2\n",
      "4\n",
      "0\n",
      "13\n",
      "4\n",
      "16\n",
      "4\n",
      "4\n",
      "2\n",
      "11\n",
      "2\n",
      "5\n",
      "4\n",
      "3\n",
      "8\n",
      "7\n",
      "7\n",
      "1\n",
      "7\n",
      "5\n",
      "7\n",
      "1\n",
      "6\n",
      "0\n",
      "10\n",
      "2\n",
      "4\n",
      "6\n",
      "4\n",
      "14\n",
      "9\n",
      "6\n",
      "7\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "7\n",
      "5\n",
      "3\n",
      "1\n",
      "4\n",
      "8\n",
      "2\n",
      "7\n",
      "5\n",
      "3\n",
      "7\n",
      "4\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "4\n",
      "12\n",
      "13\n",
      "5\n",
      "1\n",
      "7\n",
      "3\n",
      "4\n",
      "1\n",
      "4\n",
      "12\n",
      "9\n",
      "4\n",
      "3\n",
      "11\n",
      "2\n",
      "9\n",
      "0\n",
      "9\n",
      "2\n",
      "1\n",
      "2\n",
      "6\n",
      "3\n",
      "3\n",
      "1\n",
      "4\n",
      "2\n",
      "0\n",
      "3\n",
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "Xtrain_idx = []\n",
    "maxlen = 0\n",
    "for x in Xtrain:\n",
    "  Xtrain_idx.append(sent2idx(x))\n",
    "  if len(Xtrain_idx[-1]) > maxlen:\n",
    "    maxlen = len(Xtrain_idx[-1])\n",
    "  print(len(Xtrain_idx[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30226\n"
     ]
    }
   ],
   "source": [
    "vocab = [''] + vocab\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.vstack((np.random.rand(*W[0].shape), W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in enumerate(Xtrain_idx):\n",
    "  if len(x) < maxlen:\n",
    "    Xtrain_idx[i] = np.hstack((x, np.zeros(maxlen-len(x))))\n",
    "Xtrain_idx = np.array(Xtrain_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(665, 34)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(W.shape[0], W.shape[1], name='embed'))\n",
    "model.add(keras.layers.Bidirectional(keras.layers.LSTM(20, return_sequences=True)))\n",
    "model.add(keras.layers.Bidirectional(keras.layers.LSTM(8)))\n",
    "model.add(keras.layers.Dense(30, activation='relu'))\n",
    "model.add(keras.layers.Dense(2))\n",
    "\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy, optimizer=keras.optimizers.SGD(learning_rate=1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_layer('embed').set_weights([W])\n",
    "model.get_layer('embed').trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "21/21 [==============================] - 8s 41ms/step - loss: 2.4592\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 1.3946\n",
      "Epoch 3/20\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.8183\n",
      "Epoch 4/20\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.7927\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.7796\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.7557\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.7463\n",
      "Epoch 8/20\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.7421\n",
      "Epoch 9/20\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.7392\n",
      "Epoch 10/20\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.7064\n",
      "Epoch 11/20\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.6977\n",
      "Epoch 12/20\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.6946\n",
      "Epoch 13/20\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.6772\n",
      "Epoch 14/20\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.6703\n",
      "Epoch 15/20\n",
      "21/21 [==============================] - 1s 59ms/step - loss: 0.6688\n",
      "Epoch 16/20\n",
      "21/21 [==============================] - 1s 60ms/step - loss: 0.6674\n",
      "Epoch 17/20\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.6664\n",
      "Epoch 18/20\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.6652\n",
      "Epoch 19/20\n",
      "21/21 [==============================] - 1s 55ms/step - loss: 0.6643\n",
      "Epoch 20/20\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.6637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f99b79c9e10>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain_idx, Ytrain,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_idx = []\n",
    "for x in Xtest:\n",
    "  Xtest_idx.append(sent2idx(x))\n",
    "  if len(Xtest_idx[-1]) > maxlen:\n",
    "    Xtest_idx[-1] =  Xtest_idx[-1][:maxlen]\n",
    "  else:\n",
    "    Xtest_idx[-1] = np.hstack((Xtest_idx[-1], np.zeros(maxlen-len(Xtest_idx[-1]))))\n",
    "Xtest_idx = np.array(Xtest_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(Xtest_idx).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(Xtest_idx).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5244755244755245"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Ytest,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "        .master(\"local\")\\\n",
    "        .appName('word count')\\\n",
    "        .getOrCreate()\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_text=sc.textFile('/Users/macproretina132015/Desktop/text.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=in_text.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['อีสายเหลือง',\n",
       " 'อย่ามั่นหน้าว่าตัวเองสวยเลย',\n",
       " 'เค้าก็น่ารักนะ',\n",
       " 'ขุดทองแน่ๆ พวกเกย์ขุดทอง',\n",
       " 'อีบ้า สติไม่ดี',\n",
       " 'น่ารักมากกกกกก',\n",
       " 'นิสัยดีนะ',\n",
       " '']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfuture_idx = []\n",
    "for x in text:\n",
    "  Xfuture_idx.append(sent2idx(x))\n",
    "  if len(Xfuture_idx[-1]) > maxlen:\n",
    "    Xfuture_idx[-1] =  Xfuture_idx[-1][:maxlen]\n",
    "  else:\n",
    "    Xfuture_idx[-1] = np.hstack((Xfuture_idx[-1], np.zeros(maxlen-len(Xfuture_idx[-1]))))\n",
    "Xfuture_idx = np.array(Xfuture_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(Xfuture_idx).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
